<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>基于多算法融合的中文短文本主题分析实践 | 风控技术文档</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            padding-top: 4rem;
            background-color: #f8f9fa;
        }

        .doc-header {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            color: white;
            padding: 3rem 0;
            margin-bottom: 2rem;
            border-radius: 0 0 15px 15px;
        }

        .doc-toc {
            position: sticky;
            top: 2rem;
            background: white;
            border-radius: 10px;
            padding: 1.5rem;
            box-shadow: 0 5px 15px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }

        .doc-content {
            background: white;
            border-radius: 10px;
            padding: 2rem;
            box-shadow: 0 5px 15px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }

        .doc-section {
            margin-bottom: 3rem;
        }

        .doc-section h2 {
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
        }

        .doc-section h3 {
            color: var(--secondary-color);
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }

        .code-block {
            background-color: #f8f9fa;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            overflow-x: auto;
            position: relative;
        }

        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #e9ecef;
        }

        .code-lang {
            font-size: 0.85rem;
            font-weight: 600;
            color: var(--secondary-color);
            background-color: rgba(52, 152, 219, 0.1);
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
        }

        .code-copy {
            background: none;
            border: none;
            color: #6c757d;
            cursor: pointer;
            font-size: 0.85rem;
            display: flex;
            align-items: center;
        }

        .code-copy:hover {
            color: var(--secondary-color);
        }

        .code-copy.copied {
            color: var(--accent-color);
        }

        .image-container {
            text-align: center;
            margin: 2rem 0;
        }

        .image-container img {
            max-width: 100%;
            border-radius: 8px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .image-caption {
            font-style: italic;
            color: #6c757d;
            margin-top: 0.5rem;
        }

        .note-box {
            background-color: #e8f4f8;
            border-left: 4px solid var(--secondary-color);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .warning-box {
            background-color: #fef3e2;
            border-left: 4px solid var(--accent-color);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .tag {
            display: inline-block;
            background-color: #e9ecef;
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-size: 0.85rem;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
            color: var(--primary-color);
        }

        .back-to-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--secondary-color);
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            text-decoration: none;
            box-shadow: 0 3px 10px rgba(0,0,0,0.2);
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 1000;
        }

        .back-to-top.show {
            opacity: 1;
        }

        .performance-table {
            font-size: 0.9rem;
        }

        .performance-table th {
            background-color: var(--secondary-color);
            color: white;
        }

        .nav-breadcrumb {
            background-color: #f8f9fa;
            padding: 1rem 0;
            margin-bottom: 2rem;
            border-radius: 0 0 8px 8px;
        }

        .method-comparison {
            background-color: #f8f9fa;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .risk-indicator {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }

        .risk-high {
            background-color: #f8d7da;
            color: #721c24;
        }

        .risk-medium {
            background-color: #fff3cd;
            color: #856404;
        }

        .risk-low {
            background-color: #d1ecf1;
            color: #0c5460;
        }

        @media (max-width: 768px) {
            .doc-toc {
                position: static;
                margin-bottom: 2rem;
            }
        }
    </style>
</head>
<body>
    <!-- 导航栏 -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
            <a class="navbar-brand" href="#">
                <i class="bi bi-shield-check me-2"></i>内容安全分析系统
            </a>
        </div>
    </nav>

    <!-- 面包屑导航 -->
    <div class="nav-breadcrumb">
        <div class="container">
            <nav aria-label="breadcrumb">
                <ol class="breadcrumb mb-0">
                    <li class="breadcrumb-item"><a href="#">首页</a></li>
                    <li class="breadcrumb-item"><a href="#">风控工作记录</a></li>
                    <li class="breadcrumb-item active">主题分析系统</li>
                </ol>
            </nav>
        </div>
    </div>

    <!-- 文档头部 -->
    <header class="doc-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-8">
                    <span class="badge bg-light text-dark mb-2">技术文档</span>
                    <h1 class="display-5 fw-bold">基于多算法融合的中文短文本主题分析实践</h1>
                    <p class="lead">面向内容安全与舆情监控的聚类与关键词提取融合方案</p>
                    <div class="d-flex flex-wrap mt-3">
                        <span class="tag">舆情监控</span>
                        <span class="tag">内容安全</span>
                        <span class="tag">TextRank</span>
                        <span class="tag">TF-IDF</span>
                        <span class="tag">聚类分析</span>
                        <span class="tag">主题建模</span>
                    </div>
                </div>
                <div class="col-lg-4 text-lg-end">
                    <div class="text-white-50">
                        <p><i class="bi bi-calendar me-2"></i>发布日期: 2025年10月17日</p>
                        <p><i class="bi bi-person me-2"></i>作者: 风控技术团队</p>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <main class="container">
        <div class="row">
            <!-- 文档目录 -->
            <div class="col-lg-3">
                <div class="doc-toc">
                    <h5>文档目录</h5>
                    <nav id="table-of-contents">
                        <ul class="nav flex-column">
                            <li class="nav-item">
                                <a class="nav-link" href="#introduction">1. 引言</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#industry-methods">2. 业界方法综述</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#algorithm-intro">3. 核心算法详解</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#system-design">4. 系统设计与实现</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#evaluation">5. 性能评估</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#application">6. 应用与部署</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#conclusion">7. 总结</a>
                            </li>
                        </ul>
                    </nav>
                </div>
            </div>

            <!-- 文档内容 -->
            <div class="col-lg-9">
                <div class="doc-content">
                    <!-- 摘要 -->
                    <div class="alert alert-info">
                        <h5><i class="bi bi-info-circle"></i> 摘要</h5>
                        <p class="mb-0">本文详细介绍了一个面向内容安全与舆情监控的中文短文本主题分析系统。系统结合了聚类分析与多算法关键词提取技术，通过TF-IDF、TextRank、语义分析和混合方法实现了高效的主题发现和风险识别。该系统特别针对中文短文本的特点进行了优化，在内容安全和舆情监控场景中表现出色。</p>
                    </div>

                    <!-- 1. 引言 -->
                    <section id="introduction" class="doc-section">
                        <h2>1. 引言</h2>
                        <p>在当今数字化时代，内容安全和舆情监控已成为企业和政府机构不可或缺的重要工作。随着社交媒体、论坛、评论区等用户生成内容的爆炸式增长，如何从海量短文本中快速识别关键主题、发现潜在风险，成为了风控领域的核心挑战。</p>

                        <p>传统的内容审核方法主要依赖人工审核或基于规则的系统，效率低下且难以应对新型风险。本文介绍的主题分析系统通过聚类分析与多算法关键词提取的融合方案，实现了自动化、智能化的内容主题发现和风险评估。</p>

                        <div class="note-box">
                            <strong>应用场景:</strong> 该系统特别适合处理社交媒体聊天记录、用户评论、新闻评论等短文本数据，可用于内容审核、舆情监控、风险预警、用户画像构建等多个场景。
                        </div>
                    </section>

                    <!-- 2. 业界方法综述 -->
                    <section id="industry-methods" class="doc-section">
                        <h2>2. 业界方法综述</h2>

                        <h3>2.1 传统主题模型方法</h3>
                        <p>在主题分析领域，业界有多种成熟的技术方案：</p>

                        <div class="method-comparison">
                            <h5>LDA (Latent Dirichlet Allocation)</h5>
                            <p>LDA是一种经典的概率主题模型，假设每个文档由多个主题混合而成。它在处理长文本时表现良好，但对于短文本存在稀疏性问题。</p>

                            <h5>NMF (Non-negative Matrix Factorization)</h5>
                            <p>非负矩阵分解通过矩阵分解发现文本的潜在主题结构，计算效率高，但对初始值敏感。</p>

                            <h5>BERTopic</h5>
                            <p>结合BERT嵌入和聚类算法的现代主题建模方法，能够生成语义连贯的主题，但计算成本较高。</p>
                        </div>

                        <h3>2.2 基于深度学习的方法</h3>
                        <p>随着深度学习技术的发展，基于神经网络的文本分析方法日益普及：</p>

                        <ul>
                            <li><strong>预训练语言模型</strong>: 如BERT、RoBERTa等，通过在大规模语料上预训练，学习丰富的语言表示</li>
                            <li><strong>序列标注模型</strong>: 使用BiLSTM-CRF等模型进行实体识别和关键词提取</li>
                            <li><strong>图神经网络</strong>: 应用于文本关系建模，增强语义理解能力</li>
                        </ul>

                        <h3>2.3 本系统方案特点</h3>
                        <p>与上述方法相比，本系统采用聚类+多算法关键词提取的融合方案，具有以下优势：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">系统特点</span>
                            </div>
                            <pre><code class="language-plaintext">1. 专门针对中文短文本优化
2. 结合传统统计方法和现代语义分析
3. 支持多种聚类算法和关键词提取方法
4. 提供灵活的参数配置和算法组合
5. 完整的预处理和结果可视化流程</code></pre>
                        </div>

                        <div class="note-box">
                            <strong>技术选型说明:</strong> 本系统选用BAAI/bge-base-zh作为预训练模型，该模型在中文语义理解任务上表现优异，特别适合处理中文短文本。同时，系统保留了传统方法的优势，确保在不同场景下都能获得良好效果。
                        </div>
                    </section>

                    <!-- 3. 核心算法详解 -->
                    <section id="algorithm-intro" class="doc-section">
                        <h2>3. 核心算法详解</h2>

                        <h3>3.1 预训练模型简介</h3>
                        <p>本系统使用BAAI/bge-base-zh预训练模型生成文本语义表示。该模型是北京智源人工智能研究院发布的中文语义表示模型，在多项中文自然语言处理任务中表现出色，特别适合处理中文短文本的语义理解。</p>

                        <h3>3.2 TF-IDF算法</h3>
                        <p>TF-IDF（Term Frequency-Inverse Document Frequency）是一种经典的统计方法，用于评估词语在文档中的重要程度。TF表示词频，IDF表示逆文档频率。</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def method_tfidf_optimized(self, texts: List[str], top_k: int = 10) -> List[Tuple[str, float]]:
    """
    优化的TF-IDF关键词提取方法
    """
    if len(texts) < 3:
        return []

    # 分词和过滤
    segmented_texts = self._segment_and_filter(texts)
    text_strings = [' '.join(words) for words in segmented_texts]

    try:
        # 严格的TF-IDF参数
        vectorizer = TfidfVectorizer(
            max_features=100,
            stop_words=self.extended_stop_words,
            min_df=1,  # 至少在2个文档中出现
            max_df=0.7,  # 最多在70%的文档中出现
            ngram_range=(1, 2)  # 包含1-gram和2-gram
        )

        X = vectorizer.fit_transform(text_strings)
        words = vectorizer.get_feature_names_out()
        scores = np.array(X.sum(axis=0)).flatten()

        # 组合结果
        results = list(zip(words, scores))
        results.sort(key=lambda x: x[1], reverse=True)

        return results[:top_k]

    except Exception as e:
        print(f"TF-IDF提取错误: {e}")
        return []</code></pre>
                        </div>

                        <h3>3.3 TextRank算法</h3>
                        <p>TextRank是一种基于图的排序算法，灵感来源于PageRank。它将文本中的词语作为图中的节点，通过词语之间的共现关系构建边，然后计算每个节点的重要性。</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def method_textrank(self, texts: List[str], top_k: int = 10) -> List[Tuple[str, float]]:
    """
    TextRank关键词提取方法
    """
    if len(texts) < 3:
        return []

    # 合并文本
    combined_text = ' '.join([' '.join(self._segment_and_filter([text])[0]) for text in texts])

    if len(combined_text.strip()) < 10:
        return []

    try:
        # 使用jieba的TextRank实现
        keywords = jieba.analyse.textrank(
            combined_text,
            topK=top_k * 3,  # 多取一些用于过滤
            withWeight=True,
            allowPOS=('n', 'vn', 'v', 'a')  # 名词、动名词、动词、形容词
        )

        # 过滤无意义词
        filtered_keywords = []
        for word, score in keywords:
            if self._is_meaningful_word(word):
                filtered_keywords.append((word, score))
            if len(filtered_keywords) >= top_k:
                break

        return filtered_keywords

    except Exception as e:
        print(f"TextRank提取错误: {e}")
        return []</code></pre>
                        </div>

                        <h3>3.4 语义分析方法</h3>
                        <p>基于预训练模型的语义分析方法利用深度学习模型生成文本的语义表示，通过计算词语与整体语义中心的相似度来提取关键词。</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def method_semantic(self, texts: List[str], top_k: int = 10) -> List[Tuple[str, float]]:
    """
    基于语义的关键词提取方法
    """
    if len(texts) < 3:
        return []

    # 生成文本嵌入（如果还没有）
    if self.embeddings is None:
        processed_texts = [self.preprocess_text(text) for text in texts]
        valid_texts = [text for text in processed_texts if len(text) > 3]
        if len(valid_texts) < 3:
            return []
        self.embeddings = self.model.encode(valid_texts, show_progress_bar=True)

    # 提取候选词
    candidate_words = []
    word_occurrences = {}

    segmented_texts = self._segment_and_filter(texts)

    for i, words in enumerate(segmented_texts):
        for word in words:
            if word not in candidate_words:
                candidate_words.append(word)
            if word not in word_occurrences:
                word_occurrences[word] = []
            word_occurrences[word].append(i)

    # 过滤低频词
    candidate_words = [word for word in candidate_words if len(word_occurrences[word]) >= 2]

    if not candidate_words:
        return []

    # 计算词向量（通过包含该词的文本向量的平均）
    word_vectors = []
    valid_candidates = []

    for word in candidate_words:
        indices = word_occurrences[word]
        if len(indices) <= len(self.embeddings):
            word_vector = self.embeddings[indices].mean(axis=0)
            word_vectors.append(word_vector)
            valid_candidates.append(word)

    if not valid_candidates:
        return []

    word_vectors = np.array(word_vectors)

    # 计算与整体语义中心的相似度
    text_center = self.embeddings.mean(axis=0)
    similarities = cosine_similarity(word_vectors, [text_center]).flatten()

    # 组合结果
    results = list(zip(valid_candidates, similarities))
    results.sort(key=lambda x: x[1], reverse=True)

    return results[:top_k]</code></pre>
                        </div>

                        <h3>3.5 混合方法</h3>
                        <p>混合方法综合了TF-IDF、TextRank和语义分析三种方法的优势，通过加权投票机制得到最终的关键词排名。</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def method_hybrid(self, texts: List[str], top_k: int = 10) -> List[Tuple[str, float]]:
    """
    混合方法（加权投票）
    """
    if len(texts) < 3:
        return []

    # 获取各种方法的结果
    tfidf_results = self.method_tfidf_optimized(texts, top_k * 3)
    textrank_results = self.method_textrank(texts, top_k * 3)
    semantic_results = self.method_semantic(texts, top_k * 3)

    # 投票得分系统
    keyword_scores = {}

    # TF-IDF得分（权重0.3）
    for i, (word, score) in enumerate(tfidf_results):
        normalized_score = 1.0 - (i / len(tfidf_results))  # 排名归一化
        keyword_scores[word] = keyword_scores.get(word, 0) + normalized_score * 0.3

    # TextRank得分（权重0.3）
    for i, (word, score) in enumerate(textrank_results):
        normalized_score = 1.0 - (i / len(textrank_results))
        keyword_scores[word] = keyword_scores.get(word, 0) + normalized_score * 0.3

    # 语义得分（权重0.4）
    for i, (word, score) in enumerate(semantic_results):
        normalized_score = 1.0 - (i / len(semantic_results))
        keyword_scores[word] = keyword_scores.get(word, 0) + normalized_score * 0.4

    # 按总分排序
    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)

    return [(word, score) for word, score in sorted_keywords[:top_k]]</code></pre>
                        </div>
                    </section>

                    <!-- 4. 系统设计与实现 -->
                    <section id="system-design" class="doc-section">
                        <h2>4. 系统设计与实现</h2>

                        <h3>4.1 系统架构</h3>
                        <p>主题分析系统的整体架构包括数据预处理、嵌入生成、聚类分析和主题生成四个核心模块：</p>

                        <div class="image-container">
                            <div style="background:#f0f0f0; padding:2rem; border-radius:8px; text-align:center;">
                                <p>数据输入 → 文本预处理 → 嵌入生成 → 聚类分析 → 主题生成 → 结果输出</p>
                                <p>↑</p>
                                <p>多算法关键词提取 (TF-IDF + TextRank + 语义分析 + 混合方法)</p>
                            </div>
                            <div class="image-caption">图1: 系统架构示意图</div>
                        </div>

                        <h3>4.2 聚类分析</h3>
                        <p>系统支持KMeans和DBSCAN两种聚类算法，并包含自动确定最佳聚类数量的功能：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def cluster_texts(self, n_clusters: int = None, method: str = 'kmeans') -> np.ndarray:
    """
    对文本进行聚类
    """
    if self.embeddings is None:
        self.generate_embeddings()

    if method == 'kmeans':
        if n_clusters is None:
            # 使用肘部法则确定聚类数量
            n_clusters = self._find_optimal_clusters()
            print(f"自动确定的聚类数量: {n_clusters}")

        clusterer = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        self.cluster_labels = clusterer.fit_predict(self.embeddings)

    elif method == 'dbscan':
        # 使用UMAP降维后再进行DBSCAN聚类
        reducer = umap.UMAP(n_components=50, random_state=42)
        reduced_embeddings = reducer.fit_transform(self.embeddings)

        clusterer = DBSCAN(eps=0.5, min_samples=5)
        self.cluster_labels = clusterer.fit_predict(reduced_embeddings)

    # 将聚类标签添加到DataFrame中
    self.df['cluster'] = -2  # 初始化为-2（无效文本）
    self.df.loc[self.valid_indices, 'cluster'] = self.cluster_labels

    print(f"聚类完成，共 {len(set(self.cluster_labels))} 个聚类")
    return self.cluster_labels</code></pre>
                        </div>

                        <h3>4.3 主题标签生成</h3>
                        <p>基于关键词和文本内容特征，自动生成有意义的主题标签：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def generate_topic_labels(self, cluster_texts: List[str], keywords: List[str]) -> str:
    """
    为每个聚类生成有意义的主题标签
    """
    if not cluster_texts or not keywords:
        return "未定义主题"

    # 分析文本内容特征
    text_samples = ' '.join(cluster_texts[:20])  # 取前20个样本进行分析

    # 基于关键词和文本内容生成主题标签
    if any(word in text_samples for word in ['唱歌', '声音', '听歌', '音乐', '好听']):
        return "音乐娱乐"
    elif any(word in text_samples for word in ['睡觉', '休息', '起床', '晚安', '熬夜']):
        return "作息生活"
    elif any(word in text_samples for word in ['吃饭', '餐厅', '美食', '火锅', '外卖']):
        return "饮食话题"
    # ... 更多类别判断
    else:
        # 如果没有匹配到特定类别，使用前3个关键词生成标签
        return f"{'、'.join(keywords[:3])}相关"</code></pre>
                        </div>
                    </section>

                    <!-- 5. 性能评估 -->
                    <section id="evaluation" class="doc-section">
                        <h2>5. 性能评估</h2>

                        <h3>5.1 关键词提取方法对比</h3>
                        <p>我们在相同数据集上对比了四种关键词提取方法的性能：</p>

                        <table class="table table-bordered performance-table">
                            <thead>
                                <tr>
                                    <th>方法</th>
                                    <th>关键词质量</th>
                                    <th>处理速度</th>
                                    <th>内存占用</th>
                                    <th>适用场景</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>TF-IDF</td>
                                    <td>中等</td>
                                    <td>快速</td>
                                    <td>低</td>
                                    <td>通用文本、大规模数据</td>
                                </tr>
                                <tr>
                                    <td>TextRank</td>
                                    <td>良好</td>
                                    <td>中等</td>
                                    <td>中等</td>
                                    <td>长文本、连贯性强的文本</td>
                                </tr>
                                <tr>
                                    <td>语义分析</td>
                                    <td>优秀</td>
                                    <td>较慢</td>
                                    <td>高</td>
                                    <td>短文本、语义复杂的文本</td>
                                </tr>
                                <tr>
                                    <td>混合方法</td>
                                    <td>最优</td>
                                    <td>中等</td>
                                    <td>高</td>
                                    <td>高质量关键词提取、重要场景</td>
                                </tr>
                            </tbody>
                        </table>

                        <h3>5.2 舆情监控效果</h3>
                        <p>系统在舆情监控场景中的实际分析效果：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">文本</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-plaintext">【主题 0】负面评价
  - 规模: 856 条消息 (8.6%)
  - 关键词: 差评, 垃圾, 不好用, 坑人, 骗钱, 退货
  - 风险等级: <span class="risk-indicator risk-high">高</span>
  - 代表性内容:
      1. 这个产品太差了，根本不好用
      2. 商家骗钱，大家不要上当
      3. 我要退货，质量太差了

【主题 1】敏感话题
  - 规模: 324 条消息 (3.2%)
  - 关键词: 政治, 领导人, 政府, 抗议, 不满, 言论
  - 风险等级: <span class="risk-indicator risk-high">高</span>
  - 代表性内容:
      1. 对当前政策有些不同看法
      2. 领导人的这个决策不太合理
      3. 我们应该有更多言论自由

【主题 2】产品咨询
  - 规模: 1,247 条消息 (12.5%)
  - 关键词: 咨询, 价格, 功能, 使用, 购买, 售后
  - 风险等级: <span class="risk-indicator risk-low">低</span>
  - 代表性内容:
      1. 这个产品有什么功能？
      2. 价格是多少？有优惠吗？
      3. 售后政策怎么样？</code></pre>
                        </div>

                        <h3>5.3 可视化分析</h3>
                        <p>系统提供聚类结果的可视化功能，帮助理解主题分布：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">def visualize_clusters(self, save_path: str = None):
    """
    可视化聚类结果
    """
    if self.embeddings is None or self.cluster_labels is None:
        raise ValueError("请先生成嵌入向量并进行聚类")

    # 使用PCA降维到2D进行可视化
    pca = PCA(n_components=2, random_state=42)
    embeddings_2d = pca.fit_transform(self.embeddings)

    plt.figure(figsize=(12, 8))

    # 创建颜色映射
    unique_clusters = set(self.cluster_labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))

    for i, cluster_id in enumerate(unique_clusters):
        if cluster_id == -1:  # 噪声点
            color = 'gray'
            label = 'Noise'
            alpha = 0.3
        else:
            color = colors[i]
            label = f'Topic {cluster_id}'
            alpha = 0.7

        mask = self.cluster_labels == cluster_id
        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],
                    c=[color], label=label, alpha=alpha, s=30)

    plt.title('Chat Topics Clustering Visualization', fontsize=16, fontweight='bold')
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"可视化图已保存至: {save_path}")

    plt.show()</code></pre>
                        </div>

                        <div class="image-container">
                            <img src="topic_clusters.png" alt="主题聚类可视化结果">
                            <div class="image-caption">图2: 主题聚类可视化结果</div>
                        </div>
                    </section>

                    <!-- 6. 应用与部署 -->
                    <section id="application" class="doc-section">
                        <h2>6. 应用与部署</h2>

                        <h3>6.1 完整分析流程</h3>
                        <p>系统提供完整的主题分析流程，从数据加载到结果生成：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python"># 初始化分析器
analyzer = ChatTopicAnalyzer(model_name='BAAI/bge-base-zh')

# 1. 加载数据
csv_file = 'test.csv'#包含msg字段
df = analyzer.load_data(csv_file)

# 2. 生成嵌入向量
print("正在生成文本嵌入向量...")
analyzer.generate_embeddings()

# 3. 聚类分析
print("正在进行文本聚类...")
analyzer.cluster_texts(method='kmeans', n_clusters=20)

# 4. 主题分析（使用混合方法提取关键词）
print("正在分析主题...")
topic_analysis = analyzer.analyze_topics(keyword_method='hybrid')

# 5. 保存主题明细CSV文件
print("正在保存主题明细...")
topic_details = analyzer.save_topic_details('topic_details.csv')

# 6. 可视化
print("生成可视化图表...")
analyzer.visualize_clusters('topic_clusters.png')

# 7. 生成报告
print("生成分析报告...")
analyzer.generate_report(topic_analysis, 'topic_analysis_report.txt')</code></pre>
                        </div>

                        <h3>6.2 舆情监控集成</h3>
                        <p>系统可以方便地集成到舆情监控平台中：</p>

                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-lang">Python</span>
                                <button class="code-copy"><i class="bi bi-clipboard"></i> 复制</button>
                            </div>
                            <pre><code class="language-python">class PublicOpinionMonitor:
    def __init__(self, topic_analyzer):
        self.analyzer = topic_analyzer
        self.risk_keywords = {
            'high': ['诈骗', '骗钱', '垃圾', '差评', '抗议', '政治'],
            'medium': ['不满', '投诉', '问题', '缺点', '不好'],
            'low': ['咨询', '建议', '疑问', '了解']
        }

    def assess_risk_level(self, topic_analysis):
        """评估主题风险等级"""
        risk_assessment = {}

        for topic_id, analysis in topic_analysis.items():
            risk_score = 0
            keywords = analysis['keywords']

            # 根据关键词计算风险分数
            for word in keywords:
                if word in self.risk_keywords['high']:
                    risk_score += 3
                elif word in self.risk_keywords['medium']:
                    risk_score += 2
                elif word in self.risk_keywords['low']:
                    risk_score += 1

            # 确定风险等级
            if risk_score >= 5:
                risk_level = '高'
            elif risk_score >= 3:
                risk_level = '中'
            else:
                risk_level = '低'

            risk_assessment[topic_id] = {
                'risk_score': risk_score,
                'risk_level': risk_level,
                'topic_label': analysis['topic_label']
            }

        return risk_assessment</code></pre>
                        </div>
                    </section>

                    <!-- 7. 总结 -->
                    <section id="conclusion" class="doc-section">
                        <h2>7. 总结</h2>

                        <p>本文详细介绍了基于多算法融合的中文短文本主题分析系统，特别针对内容安全和舆情监控场景进行了优化。该系统通过聚类分析与多算法关键词提取的融合方案，实现了高效准确的主题发现和风险评估。</p>

                        <h3>7.1 技术亮点</h3>
                        <ul>
                            <li><strong>多算法融合</strong>: 综合TF-IDF、TextRank、语义分析和混合方法的优势</li>
                            <li><strong>中文优化</strong>: 针对中文短文本特点进行专门优化</li>
                            <li><strong>智能聚类</strong>: 支持自动确定最佳聚类数量</li>
                            <li><strong>语义理解</strong>: 利用预训练模型增强语义理解能力</li>
                            <li><strong>完整流程</strong>: 提供从数据预处理到结果可视化的完整解决方案</li>
                        </ul>

                        <h3>7.2 在内容安全中的应用价值</h3>
                        <p>该系统在内容安全和舆情监控领域具有重要应用价值：</p>
                        <ul>
                            <li><strong>风险内容识别</strong>: 自动发现负面评价、敏感话题等风险内容</li>
                            <li><strong>舆情趋势分析</strong>: 实时监控舆情动态，发现热点话题</li>
                            <li><strong>自动化审核</strong>: 减少人工审核工作量，提高审核效率</li>
                            <li><strong>预警机制</strong>: 对高风险内容进行及时预警</li>
                        </ul>

                        <div class="note-box">
                            <strong>未来展望:</strong> 未来我们将探索更多先进的主题建模技术，进一步提升系统的准确性和实用性。同时，我们计划增加实时分析能力和更丰富的可视化功能，为内容安全和舆情监控提供更强大的技术支持。
                        </div>
                    </section>
                </div>
            </div>
        </div>
    </main>

    <!-- 返回顶部按钮 -->
    <a href="#" class="back-to-top">
        <i class="bi bi-arrow-up"></i>
    </a>

    <!-- 页脚 -->
    <footer class="bg-dark text-white py-5 mt-5">
        <div class="container">
            <div class="row">
                <div class="col-lg-6">
                    <h5>风控内容安全技术文档</h5>
                    <p>分享最前沿的内容安全技术与实践</p>
                </div>
                <div class="col-lg-6 text-lg-end">
                    <p>© 2025 风控技术团队. 保留所有权利.</p>
                    <p>
                        <a href="#" class="text-white me-2"><i class="bi bi-github"></i></a>
                        <a href="#" class="text-white me-2"><i class="bi bi-linkedin"></i></a>
                        <a href="#" class="text-white"><i class="bi bi-envelope"></i></a>
                    </p>
                </div>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        // 初始化代码高亮
        hljs.highlightAll();

        // 返回顶部按钮功能
        const backToTop = document.querySelector('.back-to-top');

        window.addEventListener('scroll', function() {
            if (window.pageYOffset > 300) {
                backToTop.classList.add('show');
            } else {
                backToTop.classList.remove('show');
            }
        });

        backToTop.addEventListener('click', function(e) {
            e.preventDefault();
            window.scrollTo({top: 0, behavior: 'smooth'});
        });

        // 代码复制功能
        document.querySelectorAll('.code-copy').forEach(button => {
            button.addEventListener('click', function() {
                const codeBlock = this.closest('.code-block');
                const code = codeBlock.querySelector('code').innerText;

                // 复制到剪贴板
                navigator.clipboard.writeText(code)
                    .then(() => {
                        // 显示复制成功反馈
                        const originalText = this.innerHTML;
                        this.innerHTML = '<i class="bi bi-check"></i> 已复制';
                        this.classList.add('copied');

                        // 2秒后恢复原始状态
                        setTimeout(() => {
                            this.innerHTML = originalText;
                            this.classList.remove('copied');
                        }, 2000);
                    })
                    .catch(err => {
                        console.error('复制失败:', err);
                    });
            });
        });
    </script>
</body>
</html>